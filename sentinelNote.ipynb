{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMaZKfPvxDQrP8Xold9gd7W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/the-Soke/Sentinel-model/blob/main/sentinelNote.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YftS3IBfWFAo",
        "outputId": "965eb451-7c76-4071-b276-6b2d2441fe79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Sentinel-model'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (3/3), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/the-Soke/Sentinel-model.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/Sentinel-model\")\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsJLbucpWWcS",
        "outputId": "ab0bd684-bd53-4c25-c3b6-9e9b0ebdc0ae"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Sentinel-model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knv3e6KsWWfU",
        "outputId": "f26a79d1-aa24-42fa-a45c-5c2e1072b570"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/drive/MyDrive/nigeria_insecurity_dataset.csv\" \"/content/Sentinel-model/\"\n"
      ],
      "metadata": {
        "id": "xHh6qmxkWWi0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"nigeria_insecurity_dataset.csv\")\n",
        "\n",
        "# -----------------------------------------------\n",
        "# 1. CLEANING SECTION\n",
        "# -----------------------------------------------\n",
        "\n",
        "# Convert Date → datetime\n",
        "df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
        "\n",
        "# Extract date features\n",
        "df[\"DayOfYear\"] = df[\"Date\"].dt.dayofyear\n",
        "df[\"Month\"] = df[\"Date\"].dt.month\n",
        "df[\"Week\"] = df[\"Date\"].dt.isocalendar().week.astype(int)\n",
        "\n",
        "# Clean TimeOfDay\n",
        "# Expected formats: \"14:30\", \"2pm\", \"7AM\", etc.\n",
        "def extract_hour(t):\n",
        "    if pd.isna(t):\n",
        "        return np.nan\n",
        "    t = str(t).strip().lower()\n",
        "\n",
        "    # Case: \"14:30\" or \"07:00\"\n",
        "    if \":\" in t:\n",
        "        try:\n",
        "            return int(t.split(\":\")[0])\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    # Case: \"2pm\", \"11am\"\n",
        "    if \"am\" in t or \"pm\" in t:\n",
        "        try:\n",
        "            h = int(\"\".join([c for c in t if c.isdigit()]))\n",
        "            if \"pm\" in t and h != 12:\n",
        "                h += 12\n",
        "            if \"am\" in t and h == 12:\n",
        "                h = 0\n",
        "            return h\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    # Last fallback: try integer\n",
        "    try:\n",
        "        return int(t)\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "df[\"Hour\"] = df[\"TimeOfDay\"].apply(extract_hour)\n",
        "df[\"Hour\"] = df[\"Hour\"].fillna(df[\"Hour\"].median()).astype(int)\n",
        "\n",
        "# -----------------------------------------------\n",
        "# 2. ENCODING CATEGORICAL VARIABLES\n",
        "# -----------------------------------------------\n",
        "\n",
        "label_cols = [\"State\", \"Location\", \"WeaponsUsed\"]\n",
        "\n",
        "encoders = {}\n",
        "for col in label_cols:\n",
        "    enc = LabelEncoder()\n",
        "    df[col] = df[col].astype(str)\n",
        "    df[col] = enc.fit_transform(df[col])\n",
        "    encoders[col] = enc\n",
        "\n",
        "# -----------------------------------------------\n",
        "# 3. ENSURE NUMERIC COLUMNS\n",
        "# -----------------------------------------------\n",
        "\n",
        "numeric_cols = [\"Casualties\", \"Kidnapped\", \"PastIncidentsInArea\"]\n",
        "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
        "df[numeric_cols] = df[numeric_cols].fillna(0)\n",
        "\n",
        "# -----------------------------------------------\n",
        "# 4. FINAL DATASET PREP\n",
        "# -----------------------------------------------\n",
        "\n",
        "feature_cols = [\n",
        "    \"State\",\n",
        "    \"Location\",\n",
        "    \"WeaponsUsed\",\n",
        "    \"Casualties\",\n",
        "    \"Kidnapped\",\n",
        "    \"PastIncidentsInArea\",\n",
        "    \"DayOfYear\",\n",
        "    \"Month\",\n",
        "    \"Week\",\n",
        "    \"Hour\"\n",
        "]\n",
        "\n",
        "X = df[feature_cols]"
      ],
      "metadata": {
        "id": "rVB-J-8MXlZ2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mUs7c7jNYoiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cd3559c"
      },
      "source": [
        "# Task\n",
        "Encode the 'RiskLevel' column using `LabelEncoder` to convert its string values ('High', 'Medium', 'Low') into numerical representations, and then assign the encoded column to the target variable `y`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02dae235"
      },
      "source": [
        "## Encode RiskLevel column\n",
        "\n",
        "### Subtask:\n",
        "Apply `LabelEncoder` to the 'RiskLevel' column to convert its categorical string values (e.g., 'High', 'Medium', 'Low') into numerical representations. This will be done before assigning it to the target variable `y`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c965aa9"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires encoding the 'RiskLevel' column from categorical strings to numerical representations using `LabelEncoder` before assigning it to the target variable `y`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da9ac639"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Create an instance of LabelEncoder\n",
        "risk_level_encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform the 'RiskLevel' column\n",
        "df['RiskLevel_encoded'] = risk_level_encoder.fit_transform(df['RiskLevel'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d23af8f2"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask specifies that after encoding the 'RiskLevel' column, it should be assigned to the target variable 'y'. This step completes that requirement.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a356207"
      },
      "source": [
        "y = df[\"RiskLevel_encoded\"]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36660295"
      },
      "source": [
        "## Build and Evaluate Model\n",
        "\n",
        "### Subtask:\n",
        "Proceed with building and evaluating the machine learning model now that the target variable `y` has been correctly encoded and assigned.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33c2e2d4"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires splitting the data, initializing and fitting a RandomForestClassifier model, and then evaluating its accuracy, all of which can be done in a single Python code block using the existing variables and imported libraries.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f8557f5",
        "outputId": "0a8e5062-5869-4aff-ac4c-4994f18d12b3"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 1. TRAIN/TEST SPLIT\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 2. BUILD MODEL\n",
        "model = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=20,\n",
        "    class_weight=\"balanced\",\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 3. FIT MODEL\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 4. PRINT TRAINING COMPLETE MESSAGE\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# 5. CALCULATE AND PRINT ACCURACY\n",
        "print(\"Accuracy:\", model.score(X_test, y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete.\n",
            "Accuracy: 0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "187a6854"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The `RiskLevel` column, containing categorical string values such as 'High', 'Medium', and 'Low', was successfully encoded into numerical representations using `LabelEncoder`. These encoded values were stored in a new column, `RiskLevel_encoded`, and subsequently assigned to the target variable `y`.\n",
        "*   A `RandomForestClassifier` model was built and trained using a train/test split (80% training, 20% testing) with `n_estimators=300`, `max_depth=20`, and `class_weight=\"balanced\"`.\n",
        "*   The trained model achieved an accuracy of approximately 96.67% on the test set.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The high accuracy of 96.67% on the test set suggests that the `RandomForestClassifier` model is highly effective at predicting risk levels based on the provided features.\n",
        "*   To further validate the model's robustness and understand its performance across different risk levels, it would be beneficial to evaluate additional metrics such as precision, recall, F1-score, and a confusion matrix, especially given the use of `class_weight=\"balanced\"`.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "from skl2onnx import convert_sklearn\n",
        "from skl2onnx.common.data_types import FloatTensorType\n",
        "\n",
        "# -----------------------------------------------\n",
        "# 7. EXPORT AS ONNX\n",
        "# -----------------------------------------------\n",
        "\n",
        "initial_type = [(\"input\", FloatTensorType([None, X.shape[1]]))]\n",
        "onnx_model = convert_sklearn(model, initial_types=initial_type)\n",
        "\n",
        "with open(\"sentinel_model.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())\n",
        "\n",
        "print(\"ONNX model exported as sentinel_model.onnx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HVYiQZYbZaO",
        "outputId": "5ddf153d-d295-40b7-cee9-a9c27138d870"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ONNX model exported as sentinel_model.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20652a8f",
        "outputId": "6e8dcb72-224d-4337-8934-bb37149fbfd0"
      },
      "source": [
        "!pip install onnx skl2onnx"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.20.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting skl2onnx\n",
            "  Downloading skl2onnx-1.19.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.12/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (4.15.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx) (0.5.4)\n",
            "Requirement already satisfied: scikit-learn>=1.1 in /usr/local/lib/python3.12/dist-packages (from skl2onnx) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1->skl2onnx) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1->skl2onnx) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1->skl2onnx) (3.6.0)\n",
            "Downloading onnx-1.20.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (18.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading skl2onnx-1.19.1-py3-none-any.whl (315 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.5/315.5 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx, skl2onnx\n",
            "Successfully installed onnx-1.20.0 skl2onnx-1.19.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3A23tpwXg70o",
        "outputId": "3fd06bb4-1f24-44de-9448-6d659cf36569"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1.2M\n",
            "-rw------- 1 root root  23K Dec 12 20:58 nigeria_insecurity_dataset.csv\n",
            "-rw-r--r-- 1 root root   54 Dec 12 20:57 README.md\n",
            "-rw-r--r-- 1 root root 1.2M Dec 12 21:30 sentinel_model.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.move(\"/content/sentinelNote.ipynb\", \"/content/Sentinel-model/your_notebook.ipynb\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "Kx8PPSU0hKE2",
        "outputId": "598d96e8-0c1c-4de1-8b06-8bcaa85e519a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/sentinelNote.ipynb'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    846\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/sentinelNote.ipynb' -> '/content/Sentinel-model/your_notebook.ipynb'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1331281239.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/sentinelNote.ipynb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/Sentinel-model/your_notebook.ipynb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m             \u001b[0mcopy_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mcopy2\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m     \u001b[0mcopystat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/sentinelNote.ipynb'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.name \"the-Soke\"\n",
        "!git config --global user.email \"kesibosoke@gmail.com\"\n"
      ],
      "metadata": {
        "id": "NL4uMknlh-AB"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git add .\n"
      ],
      "metadata": {
        "id": "Vb0US26YiLFi"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"Add notebook, dataset, and scripts\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3usrxweqiRhu",
        "outputId": "4b5c5f55-c881-4c9e-dfcb-ad5201379392"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main 3105f57] Add notebook, dataset, and scripts\n",
            " 2 files changed, 301 insertions(+)\n",
            " create mode 100644 nigeria_insecurity_dataset.csv\n",
            " create mode 100644 sentinel_model.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#push here"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJoHcah5kOr0",
        "outputId": "1991a541-85ff-4120-fd0c-28b8752f51b2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enumerating objects: 5, done.\n",
            "Counting objects:  20% (1/5)\rCounting objects:  40% (2/5)\rCounting objects:  60% (3/5)\rCounting objects:  80% (4/5)\rCounting objects: 100% (5/5)\rCounting objects: 100% (5/5), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects:  25% (1/4)\rCompressing objects:  50% (2/4)\rCompressing objects:  75% (3/4)\rCompressing objects: 100% (4/4)\rCompressing objects: 100% (4/4), done.\n",
            "Writing objects:  25% (1/4)\rWriting objects:  50% (2/4)\rWriting objects:  75% (3/4)\rWriting objects: 100% (4/4)\rWriting objects: 100% (4/4), 85.18 KiB | 2.13 MiB/s, done.\n",
            "Total 4 (delta 0), reused 0 (delta 0), pack-reused 0\n",
            "To https://github.com/the-Soke/Sentinel-model.git\n",
            "   4b783af..3105f57  main -> main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0588b1a0",
        "outputId": "bfae54a2-8071-450d-ec63-4862b097a62e"
      },
      "source": [
        "!ls -F /content/"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive/\tsample_data/  Sentinel-model/\n"
          ]
        }
      ]
    }
  ]
}